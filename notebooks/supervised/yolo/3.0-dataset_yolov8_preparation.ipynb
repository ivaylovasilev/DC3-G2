{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec393f9-06db-4c1c-9c80-703a01c3f0f3",
   "metadata": {},
   "source": [
    "# Dataset Preparation for YOLOv8 models\n",
    "\n",
    "In this notebook, some tools are provided to generate datasets directly usable by YOLOv8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21451d-80a4-4f8d-940f-185556877e01",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16f10d-4c21-4721-9b4c-aab466146c3b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32772b73-78cb-49f0-8628-ee59486dd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de03d90-27b7-4d1e-ba5c-7cc1231bb6b0",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "\n",
    "Adjust the `INPUT_DIR_YOLOV8_INSTANCE_SEGMENTATION_LABELS`, `OUTPUT_DIR_YOLOV8_SEGMENTATION`, `INPUT_LABEL_MISMATCH_CSV_DATA` and `INPUT_DIR_DATASET_ROOT_RS_LABELLED` path to match your filesystem setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f1f189-5833-45cc-9ca7-f789b8f7f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Modify these four paths to point to your own data\n",
    "INPUT_DIR_DATASET_ROOT_RS_LABELLED = Path(\n",
    "    \"/home/chouffe/playground/datasets/benthic_datasets/mask_labels/rs_labelled\"\n",
    ")\n",
    "INPUT_DIR_YOLOV8_INSTANCE_SEGMENTATION_LABEL = Path(\n",
    "    \"/home/chouffe/playground/datasets/yolov8/benthic_datasets/instance_segmentation\"\n",
    ")\n",
    "INPUT_LABEL_MISMATCH_CSV_DATA = Path(\n",
    "    \"/home/chouffe/fruitpunch/challenges/coralreefs2/datasets/benthic_datasets/label_mismatch/data.csv\"\n",
    ")\n",
    "OUTPUT_DIR_YOLOV8_SEGMENTATION = Path(\n",
    "    \"/home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/\"\n",
    ")\n",
    "\n",
    "ALL_DATASETS = [\n",
    "    \"SEAFLOWER_BOLIVAR\",\n",
    "    \"SEAFLOWER_COURTOWN\",\n",
    "    \"SEAVIEW_ATL\",\n",
    "    \"SEAVIEW_IDN_PHL\",\n",
    "    \"SEAVIEW_PAC_AUS\",\n",
    "    \"SEAVIEW_PAC_USA\",\n",
    "    \"TETES_PROVIDENCIA\",\n",
    "]\n",
    "\n",
    "LABEL_TO_CLASS_MAPPING = {\"soft_coral\": 0, \"hard_coral\": 1}\n",
    "CLASS_TO_LABEL_MAPPING = {v: k for k, v in LABEL_TO_CLASS_MAPPING.items()}\n",
    "\n",
    "# For type hints\n",
    "Quadratid = int\n",
    "Contour = np.ndarray\n",
    "Mask = np.ndarray\n",
    "Polygon = np.ndarray\n",
    "Entry = list[dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8ee2e-a25c-4405-8995-958d09632f65",
   "metadata": {},
   "source": [
    "### Check folder structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b56797-f62e-40f3-a733-372a2a0678fb",
   "metadata": {},
   "source": [
    "Make sure that the following command returns something like this:\n",
    "\n",
    "```\n",
    "├── SEAFLOWER_BOLIVAR\n",
    "│   └── labels\n",
    "│       ├── images\n",
    "│       ├── individual\n",
    "│       └── stitched\n",
    "├── SEAFLOWER_COURTOWN\n",
    "│   └── labels\n",
    "│       ├── images\n",
    "│       ├── individual\n",
    "│       └── stitched\n",
    "├── SEAVIEW_ATL\n",
    "│   └── labels\n",
    "│       ├── images\n",
    "│       ├── individual\n",
    "│       └── stitched\n",
    "├── SEAVIEW_IDN_PHL\n",
    "│   └── labels\n",
    "│       ├── images\n",
    "│       ├── individual\n",
    "│       └── stitched\n",
    "├── SEAVIEW_PAC_AUS\n",
    "│   └── labels\n",
    "│       ├── images\n",
    "│       ├── individual\n",
    "│       └── stitched\n",
    "├── SEAVIEW_PAC_USA\n",
    "│   └── labels\n",
    "│       ├── images\n",
    "│       ├── individual\n",
    "│       └── stitched\n",
    "└── TETES_PROVIDENCIA\n",
    "    └── labels\n",
    "        ├── images\n",
    "        ├── individual\n",
    "        └── stitched\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6078c06-675a-4983-808e-601d46a2cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/chouffe/playground/datasets/yolov8/benthic_datasets/instance_segmentation\u001b[0m\n",
      "├── \u001b[01;34mSEAFLOWER_BOLIVAR\u001b[0m\n",
      "│   └── \u001b[01;34mlabels\u001b[0m\n",
      "│       ├── \u001b[01;34mimages\u001b[0m\n",
      "│       ├── \u001b[01;34mindividual\u001b[0m\n",
      "│       └── \u001b[01;34mstitched\u001b[0m\n",
      "├── \u001b[01;34mSEAFLOWER_COURTOWN\u001b[0m\n",
      "│   └── \u001b[01;34mlabels\u001b[0m\n",
      "│       ├── \u001b[01;34mimages\u001b[0m\n",
      "│       ├── \u001b[01;34mindividual\u001b[0m\n",
      "│       └── \u001b[01;34mstitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_ATL\u001b[0m\n",
      "│   └── \u001b[01;34mlabels\u001b[0m\n",
      "│       ├── \u001b[01;34mimages\u001b[0m\n",
      "│       ├── \u001b[01;34mindividual\u001b[0m\n",
      "│       └── \u001b[01;34mstitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_IDN_PHL\u001b[0m\n",
      "│   └── \u001b[01;34mlabels\u001b[0m\n",
      "│       ├── \u001b[01;34mimages\u001b[0m\n",
      "│       ├── \u001b[01;34mindividual\u001b[0m\n",
      "│       └── \u001b[01;34mstitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_PAC_AUS\u001b[0m\n",
      "│   └── \u001b[01;34mlabels\u001b[0m\n",
      "│       ├── \u001b[01;34mimages\u001b[0m\n",
      "│       ├── \u001b[01;34mindividual\u001b[0m\n",
      "│       └── \u001b[01;34mstitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_PAC_USA\u001b[0m\n",
      "│   └── \u001b[01;34mlabels\u001b[0m\n",
      "│       ├── \u001b[01;34mimages\u001b[0m\n",
      "│       ├── \u001b[01;34mindividual\u001b[0m\n",
      "│       └── \u001b[01;34mstitched\u001b[0m\n",
      "└── \u001b[01;34mTETES_PROVIDENCIA\u001b[0m\n",
      "    └── \u001b[01;34mlabels\u001b[0m\n",
      "        ├── \u001b[01;34mimages\u001b[0m\n",
      "        ├── \u001b[01;34mindividual\u001b[0m\n",
      "        └── \u001b[01;34mstitched\u001b[0m\n",
      "\n",
      "35 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 3 $INPUT_DIR_YOLOV8_INSTANCE_SEGMENTATION_LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece9528-3153-46f9-ad1b-c48052ca2c5a",
   "metadata": {},
   "source": [
    "Make sure that the following command returns something like this:\n",
    "\n",
    "```\n",
    "├── SEAFLOWER_BOLIVAR\n",
    "│   ├── images\n",
    "│   ├── masks\n",
    "│   └── masks_stitched\n",
    "├── SEAFLOWER_COURTOWN\n",
    "│   ├── images\n",
    "│   ├── masks\n",
    "│   └── masks_stitched\n",
    "├── SEAVIEW_ATL\n",
    "│   ├── images\n",
    "│   ├── masks\n",
    "│   └── masks_stitched\n",
    "├── SEAVIEW_IDN_PHL\n",
    "│   ├── images\n",
    "│   ├── masks\n",
    "│   └── masks_stitched\n",
    "├── SEAVIEW_PAC_AUS\n",
    "│   ├── images\n",
    "│   ├── masks\n",
    "│   └── masks_stitched\n",
    "├── SEAVIEW_PAC_USA\n",
    "│   ├── images\n",
    "│   ├── masks\n",
    "│   └── masks_stitched\n",
    "└── TETES_PROVIDENCIA\n",
    "    ├── images\n",
    "    ├── masks\n",
    "    └── masks_stitched\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce52d582-44fd-4a2e-8c13-13d667931c5a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/chouffe/playground/datasets/benthic_datasets/mask_labels/rs_labelled\u001b[0m\n",
      "├── \u001b[01;34mSEAFLOWER_BOLIVAR\u001b[0m\n",
      "│   ├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mmasks\u001b[0m\n",
      "│   └── \u001b[01;34mmasks_stitched\u001b[0m\n",
      "├── \u001b[01;34mSEAFLOWER_COURTOWN\u001b[0m\n",
      "│   ├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mmasks\u001b[0m\n",
      "│   └── \u001b[01;34mmasks_stitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_ATL\u001b[0m\n",
      "│   ├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mmasks\u001b[0m\n",
      "│   └── \u001b[01;34mmasks_stitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_IDN_PHL\u001b[0m\n",
      "│   ├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mmasks\u001b[0m\n",
      "│   └── \u001b[01;34mmasks_stitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_PAC_AUS\u001b[0m\n",
      "│   ├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mmasks\u001b[0m\n",
      "│   └── \u001b[01;34mmasks_stitched\u001b[0m\n",
      "├── \u001b[01;34mSEAVIEW_PAC_USA\u001b[0m\n",
      "│   ├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mmasks\u001b[0m\n",
      "│   └── \u001b[01;34mmasks_stitched\u001b[0m\n",
      "└── \u001b[01;34mTETES_PROVIDENCIA\u001b[0m\n",
      "    ├── \u001b[01;34mimages\u001b[0m\n",
      "    ├── \u001b[01;34mmasks\u001b[0m\n",
      "    └── \u001b[01;34mmasks_stitched\u001b[0m\n",
      "\n",
      "28 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 3 $INPUT_DIR_DATASET_ROOT_RS_LABELLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48a5507-a263-4264-a5f5-aa4dc15fcab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_r(path: Path) -> None:\n",
    "    \"\"\"Equivalent to the bash command `rm -r $path`.\n",
    "\n",
    "    Warning: Make sure you know which folder you are clearing before running it.\n",
    "    The erased files won't go to the Trash folder.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "    if os.path.isfile(path) or os.path.islink(path):\n",
    "        os.unlink(path)\n",
    "    else:\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "\n",
    "class MyDumper(yaml.Dumper):\n",
    "    def increase_indent(self, flow=False, indentless=False):\n",
    "        return super(MyDumper, self).increase_indent(flow, False)\n",
    "\n",
    "\n",
    "def write_config_yaml(\n",
    "    path: Path,\n",
    "    X_train,\n",
    "    X_val,\n",
    "    dataset_names: list[str],\n",
    "    seed: int,\n",
    "    train_size_ratio: float,\n",
    ") -> None:\n",
    "    \"\"\"Writes the `config.yaml` file that describes the generated dataset.\"\"\"\n",
    "\n",
    "    def entries_to_dict(entries):\n",
    "        result = defaultdict(list)\n",
    "        for entry in entries:\n",
    "            result[entry[\"dataset_name\"]].append(entry[\"image_filepath\"].name)\n",
    "        return dict(result)\n",
    "\n",
    "    data = {\n",
    "        \"dataset_names\": dataset_names,\n",
    "        \"seed\": seed,\n",
    "        \"train_size_ratio\": train_size_ratio,\n",
    "        \"train_dataset_size\": len(X_train),\n",
    "        \"val_dataset_size\": len(X_val),\n",
    "        \"train_dataset\": entries_to_dict(X_train),\n",
    "        \"val_dataset\": entries_to_dict(X_val),\n",
    "    }\n",
    "\n",
    "    with open(path / \"config.yaml\", \"x\") as f:\n",
    "        yaml.dump(data, f, Dumper=MyDumper, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "\n",
    "def slurp(filepath: Path) -> str:\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def write_data_yaml(path: Path) -> None:\n",
    "    \"\"\"Writes the `data.yaml` file necessary for YOLOv8 training at `path`\n",
    "    location.\"\"\"\n",
    "    data = {\n",
    "        \"train\": \"./train/images\",\n",
    "        \"val\": \"./val/images\",\n",
    "        \"nc\": 2,\n",
    "        \"names\": [CLASS_TO_LABEL_MAPPING[i] for i in range(2)],\n",
    "    }\n",
    "    with open(path / \"data.yaml\", \"x\") as f:\n",
    "        yaml.dump(data, f, Dumper=MyDumper, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "\n",
    "def write_readme(path: Path) -> None:\n",
    "    \"\"\"Writes the README.md file of the dataset that describes how to train a\n",
    "    YOLOv8 model on it.\"\"\"\n",
    "    content = [\n",
    "        \"# README\",\n",
    "        \"\",\n",
    "        \"## Basic training\",\n",
    "        \"To train a yolo model on this dataset, follow the steps:\",\n",
    "        \"1. Install ultralytics in a virtualenv:\",\n",
    "        \"> pip install ultralytics\",\n",
    "        (\n",
    "            \"2. open data.yaml and edit `train` and `val` value to indicate an absolute\"\n",
    "            \" path (eg. /home/user/fruitpunch/datasets/train/images)\"\n",
    "        ),\n",
    "        (\n",
    "            \"3. run the following basic command to train yolo for object detection for\"\n",
    "            \" 1 epoch on the dataset:\"\n",
    "        ),\n",
    "        \"> yolo train data=./data.yaml model=yolov8n.pt epochs=1\",\n",
    "        (\n",
    "            \"4. run the following basic command to train yolo for instance segmentation\"\n",
    "            \" for 1 epoch on the dataset:\"\n",
    "        ),\n",
    "        \"> yolo train data=./data.yaml model=yolov8n-seg.pt epochs=1\",\n",
    "        \"\",\n",
    "        \"## More advanced training\",\n",
    "        \"One can use different model sizes for yolo (n, s, m, l, x):\",\n",
    "        \"Eg. Train for 10 epochs the `m` size yolo model for instance segmentation:\",\n",
    "        \"> yolo train data=./data.yaml model=yolov8m-seg.pt epochs=10\",\n",
    "        \"Eg. Train for 10 epochs the `x` size yolo model for object detection:\",\n",
    "        \"> yolo train data=./data.yaml model=yolov8x.pt epochs=10\",\n",
    "    ]\n",
    "    with open(path / \"README.md\", \"x\") as f:\n",
    "        f.write(\"\\n\".join(content))\n",
    "\n",
    "\n",
    "def init_yolov8_dataset_folder_structure(\n",
    "    output_dir: Path = OUTPUT_DIR_YOLOV8_SEGMENTATION, clear: bool = True\n",
    ") -> None:\n",
    "    \"\"\"Creates the right yolov8 dataset empty folder structure.\"\"\"\n",
    "    if clear:\n",
    "        print(f\"clearing folder {output_dir}\")\n",
    "        rm_r(output_dir)\n",
    "\n",
    "    dirs = [\n",
    "        output_dir / \"train/images/\",\n",
    "        output_dir / \"train/labels/\",\n",
    "        output_dir / \"val/images/\",\n",
    "        output_dir / \"val/labels/\",\n",
    "    ]\n",
    "\n",
    "    for dir in dirs:\n",
    "        if not os.path.isdir(dir):\n",
    "            print(f\"Making directory: {dir}\")\n",
    "            os.makedirs(dir)\n",
    "\n",
    "    print(\"Writing data.yaml file\")\n",
    "    write_data_yaml(output_dir)\n",
    "    print(\"Writing README.md file\")\n",
    "    write_readme(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c7984b-8fef-4190-89ee-412a750c8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_image_filepaths(\n",
    "    dataset_name: str, input_dir: Path = INPUT_DIR_DATASET_ROOT_RS_LABELLED\n",
    ") -> list[Path]:\n",
    "    \"\"\"Returns a list of paths that are the list of all image names for a given\n",
    "    `dataset_name`.\"\"\"\n",
    "    path = input_dir / dataset_name / \"images\"\n",
    "    return [path / f for f in os.listdir(path) if os.path.isfile(path / f)]\n",
    "\n",
    "\n",
    "def is_label_mismatch(\n",
    "    dataset_name: str, invalid_seaview_quadratids: set[Quadratid], filepath: Path\n",
    ") -> bool:\n",
    "    \"\"\"Returns whether the `filepath` has a label mismatch.\"\"\"\n",
    "    if not dataset_name.startswith(\"SEAVIEW\"):\n",
    "        return False\n",
    "    elif int(filepath.stem) in invalid_seaview_quadratids:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_only_black_pixels(mask: Mask) -> bool:\n",
    "    \"\"\"Returns True if the mask image is only black pixels.\"\"\"\n",
    "    non_black_pixels = np.any(mask != [0, 0, 0], axis=-1)\n",
    "    black_pixels = ~non_black_pixels\n",
    "    return black_pixels.all()\n",
    "\n",
    "\n",
    "def get_invalid_seaview_quadratids(\n",
    "    csv_data_path: Path = INPUT_LABEL_MISMATCH_CSV_DATA,\n",
    ") -> set[Quadratid]:\n",
    "    \"\"\"Returns a set of quadratids from the seaview folders that contain label\n",
    "    mismatches.\n",
    "\n",
    "    Note:\n",
    "    ReefSupport suggested to discared the following datapoints:\n",
    "    - For Seaview, discard images with a mismatch of maximum 10 points\n",
    "      (20% if 50 annotation points or 10% if 100 annotation points)\n",
    "    - Seaflower and Tetes labelling results are best\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_data_path)\n",
    "    df_mismatch_labels = df[\n",
    "        df[\"folder\"].str.startswith(\"SEAVIEW\") & (df[\"points_mismatch_count\"] >= 10)\n",
    "    ]\n",
    "    return set(df_mismatch_labels[\"quadratid\"])\n",
    "\n",
    "\n",
    "def is_empty_label(label_filepath: Path) -> bool:\n",
    "    \"\"\"Returns true if the label file is empty (== black mask)\"\"\"\n",
    "    return (\n",
    "        (not os.path.isfile(label_filepath))\n",
    "        or slurp(label_filepath) is None\n",
    "        or slurp(label_filepath) == \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def image_filepath_to_label_filepath(dataset_name: str, image_filepath: Path) -> Path:\n",
    "    label_filename = f\"{image_filepath.stem}.txt\"\n",
    "    label_filepath = (\n",
    "        INPUT_DIR_YOLOV8_INSTANCE_SEGMENTATION_LABEL\n",
    "        / dataset_name\n",
    "        / \"labels\"\n",
    "        / \"images\"\n",
    "        / label_filename\n",
    "    )\n",
    "    return label_filepath\n",
    "\n",
    "\n",
    "def get_image_filepaths_with_empty_masks(\n",
    "    dataset_names: list[str] = ALL_DATASETS,\n",
    ") -> set[Path]:\n",
    "    \"\"\"Returns a list of image filepaths that have empty masks (= empty\n",
    "    labels).\"\"\"\n",
    "    image_filepaths_with_empty_label = set()\n",
    "    for dataset_name in dataset_names:\n",
    "        print(f\"Looking for empty masks in {dataset_name}\")\n",
    "        all_image_filepaths = list_image_filepaths(dataset_name)\n",
    "        empty_labels = [\n",
    "            image_filepath\n",
    "            for image_filepath in all_image_filepaths\n",
    "            if is_empty_label(\n",
    "                image_filepath_to_label_filepath(dataset_name, image_filepath)\n",
    "            )\n",
    "        ]\n",
    "        print(f\"    Found {len(empty_labels)} empty label files\")\n",
    "        if len(empty_labels) > 0:\n",
    "            image_filepaths_with_empty_label = image_filepaths_with_empty_label.union(\n",
    "                empty_labels\n",
    "            )\n",
    "    return image_filepaths_with_empty_label\n",
    "\n",
    "\n",
    "def get_X(\n",
    "    dataset_names: list[str],\n",
    "    invalid_seaview_quadratids: set[Quadratid],\n",
    "    invalid_image_filepaths: set[Path] = set(),\n",
    ") -> list[Entry]:\n",
    "    \"\"\"Returns a list of {dataset_name, image_filepath, label_filepath} that\n",
    "    constitues the X dataset.\n",
    "\n",
    "    Excludes the datapoints that contain data label mismatch.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    for dataset_name in dataset_names:\n",
    "        all_image_filepaths = list_image_filepaths(dataset_name)\n",
    "        image_filepaths = [\n",
    "            p\n",
    "            for p in all_image_filepaths\n",
    "            # Remove filepaths that are known to have label mismatches\n",
    "            if (not is_label_mismatch(dataset_name, invalid_seaview_quadratids, p))\n",
    "            # Remove filepaths that are invalid (empty masks for instance)\n",
    "            and (not p in invalid_image_filepaths)\n",
    "        ]\n",
    "\n",
    "        if len(all_image_filepaths) > len(image_filepaths):\n",
    "            print(\n",
    "                f\"Excluding {len(all_image_filepaths) - len(image_filepaths)} files\"\n",
    "                f\" from {dataset_name} because of label mismatch or empty masks.\"\n",
    "            )\n",
    "\n",
    "        for image_filepath in image_filepaths:\n",
    "            label_filename = f\"{image_filepath.stem}.txt\"\n",
    "            label_filepath = (\n",
    "                INPUT_DIR_YOLOV8_INSTANCE_SEGMENTATION_LABEL\n",
    "                / dataset_name\n",
    "                / \"labels\"\n",
    "                / \"images\"\n",
    "                / label_filename\n",
    "            )\n",
    "            entry = {\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"image_filepath\": image_filepath,\n",
    "                \"label_filepath\": label_filepath,\n",
    "            }\n",
    "            X.append(entry)\n",
    "    return X\n",
    "\n",
    "\n",
    "def split_train_val(\n",
    "    X: list[Entry], train_size_ratio: float = 0.8, seed: int = 42\n",
    ") -> tuple[list[Entry], list[Entry]]:\n",
    "    \"\"\"Returns a splitted dataset X into X_train and X_val using the\n",
    "    `train_size_ratio` and the random `seed`.\"\"\"\n",
    "    N = len(X)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(X)\n",
    "    split_index = int(N * train_size_ratio)\n",
    "\n",
    "    X_train, X_val = X[:split_index], X[split_index:]\n",
    "    return X_train, X_val\n",
    "\n",
    "\n",
    "def write_entry(\n",
    "    entry, mode: str = \"train\", output_dir: Path = OUTPUT_DIR_YOLOV8_SEGMENTATION\n",
    ") -> None:\n",
    "    \"\"\"Given an `entry` and a mode in #{`train`, `val`}, it writes it in a\n",
    "    YOLOv8 format.\"\"\"\n",
    "    source_image_filepath = entry[\"image_filepath\"]\n",
    "    source_label_filepath = entry[\"label_filepath\"]\n",
    "    destination_image_filepath = (\n",
    "        output_dir / mode / \"images\" / source_image_filepath.name\n",
    "    )\n",
    "    destination_label_filepath = (\n",
    "        output_dir / mode / \"labels\" / source_label_filepath.name\n",
    "    )\n",
    "\n",
    "    assert os.path.exists(\n",
    "        source_image_filepath\n",
    "    ), f\"should exist {source_image_filepath}\"\n",
    "    assert os.path.exists(\n",
    "        source_label_filepath\n",
    "    ), f\"should exist {source_label_filepath}\"\n",
    "    assert os.path.exists(\n",
    "        output_dir / mode / \"images\"\n",
    "    ), f\"the images folder should exist in {output_dir}\"\n",
    "    assert os.path.exists(\n",
    "        output_dir / mode / \"labels\"\n",
    "    ), f\"the labels folder should exist  in {output_dir}\"\n",
    "\n",
    "    shutil.copyfile(source_image_filepath, destination_image_filepath)\n",
    "    shutil.copyfile(source_label_filepath, destination_label_filepath)\n",
    "\n",
    "\n",
    "def write_dataset(\n",
    "    X_train: list[Entry],\n",
    "    X_val: list[Entry],\n",
    "    output_dir: Path = OUTPUT_DIR_YOLOV8_SEGMENTATION,\n",
    ") -> None:\n",
    "    \"\"\"Writes the dataset splitted in X_train and X_val into the right folder\n",
    "    structure for YOLOv8.\"\"\"\n",
    "    print(f\"Generating train set - {len(X_train)} datapoints\")\n",
    "    for entry in X_train:\n",
    "        write_entry(entry, mode=\"train\", output_dir=output_dir)\n",
    "\n",
    "    print(f\"Generating val set - {len(X_val)} datapoints\")\n",
    "    for entry in X_val:\n",
    "        write_entry(entry, mode=\"val\", output_dir=output_dir)\n",
    "\n",
    "\n",
    "def generate(\n",
    "    dataset_names: list[str],\n",
    "    seed: int = 42,\n",
    "    train_size_ratio: float = 0.8,\n",
    "    output_dir: Path = OUTPUT_DIR_YOLOV8_SEGMENTATION,\n",
    ") -> None:\n",
    "    \"\"\"Main function to generate the full dataset ready for YOLOv8 to be\n",
    "    trained on.\"\"\"\n",
    "    init_yolov8_dataset_folder_structure(output_dir=output_dir)\n",
    "    print(\n",
    "        \"Splitting datapoints between train and val sets for the datasets:\"\n",
    "        f\" {' '.join(dataset_names)}\"\n",
    "    )\n",
    "    invalid_seaview_quadratids = get_invalid_seaview_quadratids(\n",
    "        csv_data_path=INPUT_LABEL_MISMATCH_CSV_DATA\n",
    "    )\n",
    "    print(f\"Found {len(invalid_seaview_quadratids)} mislabelled quadratid\")\n",
    "    invalid_image_filepaths = get_image_filepaths_with_empty_masks(dataset_names)\n",
    "    print(f\"Found {len(invalid_image_filepaths)} empty masks\")\n",
    "    X = get_X(\n",
    "        dataset_names,\n",
    "        invalid_seaview_quadratids,\n",
    "        invalid_image_filepaths=invalid_image_filepaths,\n",
    "    )\n",
    "    X_train, X_val = split_train_val(X, train_size_ratio=train_size_ratio, seed=seed)\n",
    "    print(f\"Writing the data in {output_dir}\")\n",
    "    write_dataset(X_train, X_val, output_dir=output_dir)\n",
    "    print(\"Writing config.yaml file\")\n",
    "    write_config_yaml(\n",
    "        path=output_dir,\n",
    "        X_train=X_train,\n",
    "        X_val=X_val,\n",
    "        dataset_names=dataset_names,\n",
    "        seed=seed,\n",
    "        train_size_ratio=train_size_ratio,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bcb1c-c235-4b92-a17a-ad9e795e06e6",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2348e-537f-46dd-ab28-3b13e9df1776",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5524c31f-4ef5-4401-aac2-7b50915b5db8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAVIEW_ATL\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAVIEW_ATL\n",
      "    Found 328 empty label files\n",
      "Found 328 empty masks\n",
      "Excluding 72 files from SEAVIEW_ATL because of label mismatch or empty masks.\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 506 datapoints\n",
      "Generating val set - 127 datapoints\n",
      "Writing config.yaml file\n"
     ]
    }
   ],
   "source": [
    "# Add the dataset names in that list to inlude them in the generated set\n",
    "dataset_names = [\n",
    "    # \"SEAFLOWER_BOLIVAR\",\n",
    "    # 'SEAFLOWER_COURTOWN',\n",
    "    \"SEAVIEW_ATL\",\n",
    "    # 'SEAVIEW_IDN_PHL',\n",
    "    # 'SEAVIEW_PAC_AUS',\n",
    "    # 'SEAVIEW_PAC_USA',\n",
    "    # 'TETES_PROVIDENCIA',\n",
    "]\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "seed = 42\n",
    "train_size_ratio = 0.80\n",
    "# This will generate all the folder structure in `OUTPUT_DIR_YOLOV8_SEGMENTATION` for yolov8 to consume\n",
    "generate(\n",
    "    dataset_names,\n",
    "    seed=seed,\n",
    "    train_size_ratio=train_size_ratio,\n",
    "    output_dir=OUTPUT_DIR_YOLOV8_SEGMENTATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620e9b8-24c2-467e-abf1-cec0eac2d6a4",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e6cd7-92dd-4ea2-927f-9129f598a0e7",
   "metadata": {},
   "source": [
    "Below is what it should look like on your filesystem.\n",
    "\n",
    "```\n",
    "├── config.yaml\n",
    "├── data.yaml\n",
    "├── README.md\n",
    "├── train\n",
    "│   ├── images\n",
    "│   └── labels\n",
    "└── val\n",
    "    ├── images\n",
    "    └── labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b3d0ed-f90f-4e7b-b19a-395aed5344cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\u001b[0m\n",
      "├── config.yaml\n",
      "├── data.yaml\n",
      "├── README.md\n",
      "├── \u001b[01;34mtrain\u001b[0m\n",
      "│   ├── \u001b[01;34mimages\u001b[0m\n",
      "│   └── \u001b[01;34mlabels\u001b[0m\n",
      "└── \u001b[01;34mval\u001b[0m\n",
      "    ├── \u001b[01;34mimages\u001b[0m\n",
      "    └── \u001b[01;34mlabels\u001b[0m\n",
      "\n",
      "6 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "!tree -L 2 $OUTPUT_DIR_YOLOV8_SEGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6908b80-d693-4ce2-8790-57c61231bdf0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Export\n",
    "\n",
    "Export the generated dataset as a zip file to make it available anywhere (Eg. Colab instance to train on GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8d180c-6ef1-4346-8997-467c86585432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_archive(\n",
    "    output_dir: Path = OUTPUT_DIR_YOLOV8_SEGMENTATION, archive_name: str = \"archive\"\n",
    ") -> None:\n",
    "    \"\"\"Generates an archive file from the `output_dir`\"\"\"\n",
    "    shutil.make_archive(str(output_dir.parent / archive_name), \"zip\", output_dir)\n",
    "\n",
    "\n",
    "def get_archive_name(dataset_names: list[str]) -> str:\n",
    "    return f\"archive_{'_and_'.join(dataset_names)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06b0ba20-5a30-48e4-a383-55be1ed1a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_archive(archive_name=get_archive_name(dataset_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dcb220-5ec1-4d08-af65-f4ed7f63901c",
   "metadata": {},
   "source": [
    "#### Export some datasets combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36339f62-691f-4d6a-b4f3-70299bec1b92",
   "metadata": {},
   "source": [
    "##### All individual dataset regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1f928ac-32e6-43a1-ac5f-7377e7b2e16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56d71264cf14cc39e8dee385fb69d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset for TETES_PROVIDENCIA\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: TETES_PROVIDENCIA\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in TETES_PROVIDENCIA\n",
      "    Found 0 empty label files\n",
      "Found 0 empty masks\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 84 datapoints\n",
      "Generating val set - 21 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_TETES_PROVIDENCIA.zip\n",
      "Generating dataset for SEAVIEW_PAC_AUS\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAVIEW_PAC_AUS\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAVIEW_PAC_AUS\n",
      "    Found 1 empty label files\n",
      "Found 1 empty masks\n",
      "Excluding 224 files from SEAVIEW_PAC_AUS because of label mismatch or empty masks.\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 467 datapoints\n",
      "Generating val set - 117 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_SEAVIEW_PAC_AUS.zip\n",
      "Generating dataset for SEAVIEW_IDN_PHL\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAVIEW_IDN_PHL\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAVIEW_IDN_PHL\n",
      "    Found 0 empty label files\n",
      "Found 0 empty masks\n",
      "Excluding 229 files from SEAVIEW_IDN_PHL because of label mismatch or empty masks.\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 189 datapoints\n",
      "Generating val set - 48 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_SEAVIEW_IDN_PHL.zip\n",
      "Generating dataset for SEAVIEW_PAC_USA\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAVIEW_PAC_USA\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAVIEW_PAC_USA\n",
      "    Found 2 empty label files\n",
      "Found 2 empty masks\n",
      "Excluding 532 files from SEAVIEW_PAC_USA because of label mismatch or empty masks.\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 156 datapoints\n",
      "Generating val set - 40 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_SEAVIEW_PAC_USA.zip\n",
      "Generating dataset for SEAFLOWER_BOLIVAR\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAFLOWER_BOLIVAR\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAFLOWER_BOLIVAR\n",
      "    Found 1 empty label files\n",
      "Found 1 empty masks\n",
      "Excluding 1 files from SEAFLOWER_BOLIVAR because of label mismatch or empty masks.\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 196 datapoints\n",
      "Generating val set - 49 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_SEAFLOWER_BOLIVAR.zip\n",
      "Generating dataset for SEAVIEW_ATL\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAVIEW_ATL\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAVIEW_ATL\n",
      "    Found 328 empty label files\n",
      "Found 328 empty masks\n",
      "Excluding 375 files from SEAVIEW_ATL because of label mismatch or empty masks.\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 264 datapoints\n",
      "Generating val set - 66 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_SEAVIEW_ATL.zip\n",
      "Generating dataset for SEAFLOWER_COURTOWN\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAFLOWER_COURTOWN\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAFLOWER_COURTOWN\n",
      "    Found 0 empty label files\n",
      "Found 0 empty masks\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 192 datapoints\n",
      "Generating val set - 49 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_SEAFLOWER_COURTOWN.zip\n"
     ]
    }
   ],
   "source": [
    "# Add the dataset names in that list to inlude them in the generated set\n",
    "all_dataset_names = {\n",
    "    \"SEAFLOWER_BOLIVAR\",\n",
    "    \"SEAFLOWER_COURTOWN\",\n",
    "    \"SEAVIEW_ATL\",\n",
    "    \"SEAVIEW_IDN_PHL\",\n",
    "    \"SEAVIEW_PAC_AUS\",\n",
    "    \"SEAVIEW_PAC_USA\",\n",
    "    \"TETES_PROVIDENCIA\",\n",
    "}\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "seed = 42\n",
    "train_size_ratio = 0.80\n",
    "\n",
    "for dataset_name in tqdm(all_dataset_names):\n",
    "    print(f\"Generating dataset for {dataset_name}\")\n",
    "    generate(\n",
    "        [dataset_name],\n",
    "        seed=seed,\n",
    "        train_size_ratio=train_size_ratio,\n",
    "        output_dir=OUTPUT_DIR_YOLOV8_SEGMENTATION,\n",
    "    )\n",
    "    archive_name = get_archive_name([dataset_name])\n",
    "    print(f\"Making archive {archive_name}.zip\")\n",
    "    make_archive(archive_name=archive_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5480833-44be-4534-93fb-346b15a6e249",
   "metadata": {},
   "source": [
    "##### combinations of all regions but SEAVIEW_PAC_AUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb5e9fd6-897c-434c-a9aa-eb3e86870a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n",
      "clearing folder /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/train/labels\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/images\n",
      "Making directory: /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation/val/labels\n",
      "Writing data.yaml file\n",
      "Writing README.md file\n",
      "Splitting datapoints between train and val sets for the datasets: SEAFLOWER_BOLIVAR SEAFLOWER_COURTOWN SEAVIEW_ATL SEAVIEW_IDN_PHL SEAVIEW_PAC_AUS TETES_PROVIDENCIA\n",
      "Found 1054 mislabelled quadratid\n",
      "Looking for empty masks in SEAFLOWER_BOLIVAR\n",
      "    Found 1 empty label files\n",
      "Looking for empty masks in SEAFLOWER_COURTOWN\n",
      "    Found 0 empty label files\n",
      "Looking for empty masks in SEAVIEW_ATL\n",
      "    Found 328 empty label files\n",
      "Looking for empty masks in SEAVIEW_IDN_PHL\n",
      "    Found 0 empty label files\n",
      "Looking for empty masks in SEAVIEW_PAC_AUS\n",
      "    Found 1 empty label files\n",
      "Looking for empty masks in TETES_PROVIDENCIA\n",
      "    Found 0 empty label files\n",
      "Found 330 empty masks\n",
      "Excluding 1 files from SEAFLOWER_BOLIVAR because of label mismatch or empty masks.\n",
      "Excluding 375 files from SEAVIEW_ATL because of label mismatch or empty masks.\n",
      "Excluding 229 files from SEAVIEW_IDN_PHL because of label mismatch or empty masks.\n",
      "Excluding 224 files from SEAVIEW_PAC_AUS because of label mismatch or empty masks.\n",
      "Writing the data in /home/chouffe/playground/datasets/yolov8_ready/benthic_datasets/instance_segmentation\n",
      "Generating train set - 1393 datapoints\n",
      "Generating val set - 349 datapoints\n",
      "Writing config.yaml file\n",
      "Making archive archive_SEAFLOWER_BOLIVAR_and_SEAFLOWER_COURTOWN_and_SEAVIEW_ATL_and_SEAVIEW_IDN_PHL_and_SEAVIEW_PAC_AUS_and_TETES_PROVIDENCIA.zip\n"
     ]
    }
   ],
   "source": [
    "all_dataset_names_but_seaview_pac_aus = [\n",
    "    \"SEAFLOWER_BOLIVAR\",\n",
    "    \"SEAFLOWER_COURTOWN\",\n",
    "    \"SEAVIEW_ATL\",\n",
    "    \"SEAVIEW_IDN_PHL\",\n",
    "    \"SEAVIEW_PAC_AUS\",\n",
    "    \"TETES_PROVIDENCIA\",\n",
    "]\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "seed = 42\n",
    "train_size_ratio = 0.80\n",
    "\n",
    "print(f\"Generating dataset\")\n",
    "generate(\n",
    "    all_dataset_names_but_seaview_pac_aus,\n",
    "    seed=seed,\n",
    "    train_size_ratio=train_size_ratio,\n",
    "    output_dir=OUTPUT_DIR_YOLOV8_SEGMENTATION,\n",
    ")\n",
    "archive_name = get_archive_name(all_dataset_names_but_seaview_pac_aus)\n",
    "print(f\"Making archive {archive_name}.zip\")\n",
    "make_archive(archive_name=archive_name)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
